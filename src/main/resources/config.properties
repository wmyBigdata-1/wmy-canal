# canal配置
canal.server.ip=yaxin01
canal.server.port=11111
canal.server.destination=example
canal.server.username=canal
canal.server.password=canal
canal.subscribe.filter=itcast_shop.*

# zookeeper配置
zookeeper.server.ip=yaxin01:2181,yaxin02:2181

# kafka配置
# kafka集群地址
kafka.bootstrap_servers_config=yaxin01:9092,yaxin02:9092,yaxin03:9092
# 配置批次发送数据的大小，满足批次大小才会发送数据
kafka.batch_size_config=1024
# 1：表示leader节点写入成功，就返回，假设leader节点写入成功以后没有来得及同步，宕机了，数据会丢失
# 0：异步操作，不管有没有写入成功，都返回，存在丢失数据的可能
# -1：当leader节点写入成功，同时从节点同步成功以后才会返回，可以保证数据的不丢失
kafka.acks=all
# 重试次数
kafka.retries=0
kafka.client_id_config=itcast_shop_canal_clickStringSerializer
# kafka的key序列化
kafka.key_serializer_class_config=org.apache.kafka.common.serialization.StringSerializer
# kafka的value序列化，这个序列化方式是需要自定义开发的
# 这个在开发当中是可以定义在common模块中的
kafka.value_serializer_class_config=com.wmy.flink_real_warehouse.canal_client.kafka.ProtoBufSerializer
# 数据写入到kafka的哪个topic中
kafka.topic=ods_wmy_shop_mysql